{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料前處理\n",
    "\n",
    "#將為類別變數型態資料轉換為 str 型態\n",
    "#對loc_x loc_y取絕對值\n",
    "data=pd.read_csv(\"E:/WORKOUT/Statistic/data_sciense_intro/report1/train.csv\")\n",
    "data = shuffle(data)\n",
    "Y_train= np.array(data[\"action_type\"])\n",
    "test_data=pd.read_csv(\"E:/WORKOUT/Statistic/data_sciense_intro/report1/test.csv\")\n",
    "X_train = data.drop(columns=['action_type','shot_id'])\n",
    "X_train[\"playoffs\"]=X_train[\"playoffs\"].astype(\"str\")\n",
    "X_train[\"period\"]=X_train[\"period\"].astype(\"str\")\n",
    "X_train[\"season\"]=X_train[\"season\"].astype(\"str\")\n",
    "X_train['shot_made_flag']=X_train['shot_made_flag'].astype(\"str\")\n",
    "X_train['loc_x'] = X_train['loc_x'].abs()\n",
    "X_train['loc_y'] = X_train['loc_y'].abs()\n",
    "\n",
    "#將比賽日期時間更改為一串連續的浮點數\n",
    "X_train['game_date']=pd.to_datetime(X_train['game_date'])\n",
    "epoch = dt.datetime(1970, 1, 1)\n",
    "step = 0\n",
    "temp =[]\n",
    "for t in [(d - epoch).total_seconds() for d in X_train['game_date']]:\n",
    "    temp.append('%.0f' % t)  \n",
    "X_train.drop('game_date', axis = 1, inplace = True)\n",
    "X_train['game_date'] = temp\n",
    "X_train['game_date'] = X_train['game_date'].astype('float32')\n",
    "mean_game_date= X_train['game_date'].mean()\n",
    "std_game_date= X_train['game_date'].std()\n",
    "X_train['game_date'] = (X_train['game_date'] - mean_game_date) / (std_game_date)\n",
    "\n",
    "X_train = pd.get_dummies(X_train, prefix=['period','playoffs', 'season', 'shot_made_flag',\n",
    "                                          'shot_zone_area', 'opponent'])\n",
    "X_train= X_train.astype('float32')\n",
    "\n",
    "X_train =np.array(X_train)\n",
    "\n",
    "\n",
    "#  X_test\n",
    "#同上\n",
    "X_test = test_data.drop(columns=['shot_id'])\n",
    "X_test[\"playoffs\"]=X_test[\"playoffs\"].astype(\"str\")\n",
    "X_test[\"period\"]=X_test[\"period\"].astype(\"str\")\n",
    "X_test[\"season\"]=X_test[\"season\"].astype(\"str\")\n",
    "X_test['shot_made_flag']=X_test['shot_made_flag'].astype(\"str\")\n",
    "X_test['loc_x'] = X_test['loc_x'].abs()\n",
    "X_test['loc_y'] = X_test['loc_y'].abs()\n",
    "\n",
    "X_test['game_date']=pd.to_datetime(X_test['game_date'])\n",
    "\n",
    "epoch = dt.datetime(1970, 1, 1)\n",
    "step = 0\n",
    "temp =[]\n",
    "for t in [(d - epoch).total_seconds() for d in X_test['game_date']]:\n",
    "    temp.append('%.0f' % t)  \n",
    "X_test.drop('game_date', axis = 1, inplace = True)\n",
    "X_test['game_date'] = temp\n",
    "X_test['game_date'] = X_test['game_date'].astype('float32')\n",
    "X_test['game_date'] = (X_test['game_date'] - mean_game_date) / (std_game_date)\n",
    "\n",
    "X_test = pd.get_dummies(X_test, prefix=['period','playoffs', 'season', 'shot_made_flag',\n",
    "                                          'shot_zone_area', 'opponent'])\n",
    "X_test.insert(loc=13, column='period_7', value=0)\n",
    "\n",
    "X_test= X_test.astype('float32')\n",
    "\n",
    "X_test =np.array(X_test)\n",
    "\n",
    "''' Convert to one-hot encoding '''\n",
    "#將 Y (投籃型態預測) 變為dummy variable\n",
    "from keras.utils import np_utils\n",
    "Y_name ,Y_train_transform =np.unique(Y_train, return_inverse=True)\n",
    "Y_train_transform = Y_train_transform.astype('int')\n",
    "Y_train_transform = np_utils.to_categorical(Y_train_transform,57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam, RMSprop, Adagrad , adadelta, Nadam\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import Dropout\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#Self-defined Callbacks\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.loss = []\n",
    "        self.acc = []\n",
    "        self.val_loss = []\n",
    "        self.val_acc = []\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "loss_history = LossHistory()\n",
    "\n",
    "#early stopping\n",
    "#以 loss為基準  若是loss連續3次無法下降 則停止學習\n",
    "earlyStopping=EarlyStopping(monitor= 'loss', patience= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN model\n",
    "#left model\n",
    "input_1 = Input(shape = (79,))\n",
    "left = Dense(4096, )(input_1)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(2048, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(1024, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(512, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(256, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(128, kernel_regularizer=l2(0.001))(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(256, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(512, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(1024, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(2048, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dense(4096, )(left)\n",
    "left = LeakyReLU(0.02)(left)\n",
    "left = Dropout(0.4)(left)\n",
    "\n",
    "#right model\n",
    "input_2 = Input(shape = (79,))\n",
    "right = Dense(4096, )(input_2)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(2048, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(1024, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(512, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(256, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(128, kernel_regularizer=l2(0.001))(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(256, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(512, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(1024, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(2048, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dense(4096, )(right)\n",
    "right = LeakyReLU(0.02)(right)\n",
    "right = Dropout(0.4)(right)\n",
    "\n",
    "# bsbmodel - merge left and right\n",
    "bsbmodel_merge = Concatenate()([left, right])\n",
    "bsbmodel = Dense(4096, )(bsbmodel_merge)\n",
    "bsbmodel = LeakyReLU(0.02)(bsbmodel)\n",
    "bsbmodel = Dense(2048, )(bsbmodel)\n",
    "bsbmodel = LeakyReLU(0.02)(bsbmodel)\n",
    "bsbmodel = Dense(1024, )(bsbmodel)\n",
    "bsbmodel = LeakyReLU(0.02)(bsbmodel)\n",
    "bsbmodel = Dense(512, )(bsbmodel)\n",
    "bsbmodel = LeakyReLU(0.02)(bsbmodel)\n",
    "bsbmodel = Dense(256, )(bsbmodel)\n",
    "bsbmodel = LeakyReLU(0.02)(bsbmodel)\n",
    "bsbmodel = Dropout(0.4)(bsbmodel)\n",
    "\n",
    "#DNN sbs model\n",
    "input_3 = Input(shape = (79,))\n",
    "sbsmodel = Dense(128, )(input_3)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(128, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(256, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(256, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "\n",
    "sbsmodel = Dense(512, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(512, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(1024, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(1024, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "\n",
    "sbsmodel = Dense(2048, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(2048, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(4096, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dropout(0.4)(sbsmodel)\n",
    "sbsmodel = Dense(4096, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "\n",
    "sbsmodel = Dense(2048, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(2048, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(1024, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(1024, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "\n",
    "sbsmodel = Dense(512, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(512, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(256, )(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dense(256, kernel_regularizer=l2(0.001))(sbsmodel)\n",
    "sbsmodel = LeakyReLU(0.02)(sbsmodel)\n",
    "sbsmodel = Dropout(0.4)(sbsmodel)\n",
    "\n",
    "# big bsb model\n",
    "input_3 = Input(shape = (79,))\n",
    "bbsbmodel = Dense(2048, )(input_3)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(2048, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "\n",
    "bbsbmodel = Dense(1024, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(1024, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dropout(0.4)(bbsbmodel)\n",
    "bbsbmodel = Dense(512, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(512, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "\n",
    "bbsbmodel = Dense(256, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(256, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "\n",
    "bbsbmodel = Dense(128, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "\n",
    "bbsbmodel = Dense(256, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(256, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(512, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(512, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "\n",
    "bbsbmodel = Dense(1024, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(1024, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dropout(0.4)(bbsbmodel)\n",
    "bbsbmodel = Dense(2048, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dense(2048, )(bbsbmodel)\n",
    "bbsbmodel = LeakyReLU(0.02)(bbsbmodel)\n",
    "bbsbmodel = Dropout(0.4)(bbsbmodel)\n",
    "\n",
    "# merge model\n",
    "model_merge = Concatenate()([sbsmodel, bsbmodel, bbsbmodel])\n",
    "model = Dense(1024, )(bbsbmodel)\n",
    "model = LeakyReLU(0.02)(model)\n",
    "model = Dense(512, )(model)\n",
    "model = LeakyReLU(0.02)(model)\n",
    "model = Dense(256,  )(model)\n",
    "model = LeakyReLU(0.02)(model)\n",
    "\n",
    "predictions = Dense(57, activation = 'softmax')(model)\n",
    "\n",
    "model_fin = Model(inputs = [input_1, input_2, input_3], outputs = predictions)\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model_fin.compile(loss= 'categorical_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model fitting\n",
    "history_adam = model_fin.fit([X_train, X_train, X_train], Y_train_transform,\n",
    "                           batch_size = 1024,\n",
    "                           epochs = 500,\n",
    "                           verbose = 1,\n",
    "                           shuffle=True,\n",
    "                           validation_split=0.0,\n",
    "                           callbacks=[loss_history,earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model predict\n",
    "pred = model_fin.predict([X_test,X_test,X_test], verbose=1)\n",
    "pred = pred.argmax(axis=-1)\n",
    "\n",
    "#create output\n",
    "final_pred=[]\n",
    "for i in range(len(pred)):\n",
    "    final_pred.append(Y_name[pred[i]])\n",
    "output=pd.DataFrame()\n",
    "output[0]=list(test_data['shot_id'])\n",
    "output[1]=final_pred\n",
    "output.to_csv('E:/WORKOUT/Statistic/data_sciense_intro/report1/API_str3.csv', index = False, header = False)pred = model_fin.predict([X_test,X_test,X_test], verbose=1)\n",
    "pred = pred.argmax(axis=-1)\n",
    "\n",
    "#create output\n",
    "final_pred=[]\n",
    "for i in range(len(pred)):\n",
    "    final_pred.append(Y_name[pred[i]])\n",
    "output=pd.DataFrame()\n",
    "output[0]=list(test_data['shot_id'])\n",
    "output[1]=final_pred\n",
    "output.to_csv('E:/WORKOUT/Statistic/data_sciense_intro/report1/API_str3.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss val_loss acc val_acc if needed\n",
    "\n",
    "loss_adam = history_adam.history.get('loss')\n",
    "acc_adam = history_adam.history.get('acc')\n",
    "val_loss_adam = history_adam.history.get('val_loss')\n",
    "val_acc_adam = history_adam.history.get('val_acc')\n",
    " \n",
    "loss = loss_history.loss\n",
    "acc  = loss_history.acc\n",
    "val_loss = loss_history.val_loss\n",
    "val_acc  = loss_history.val_acc\n",
    " \n",
    "#''' Visualize the loss and accuracy of both models'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0)\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(loss_adam)), loss_adam,label='Training')\n",
    "plt.plot(range(len(val_loss_adam)), val_loss_adam,label='Validation')\n",
    "plt.title('Loss history returned by fit function')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(loss)), loss,label='Training')\n",
    "plt.plot(range(len(val_loss)), val_loss,label='Validation')\n",
    "plt.title('Loss history from Callbacks')\n",
    "plt.savefig('E:/WORKOUT/Statistic/data_sciense_intro/report1/DNN_model/API_merge_sbs_bsb_loss_patience1.png',dpi=300,format='png')\n",
    "plt.close()\n",
    "print('Result saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the plot\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(acc_adam)), acc_adam,label='Training')\n",
    "plt.plot(range(len(val_acc_adam)), val_acc_adam,label='Validation')\n",
    "plt.title('Acc history returned by fit function')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(acc)), loss,label='Training')\n",
    "plt.plot(range(len(val_acc)), val_acc,label='Validation')\n",
    "plt.title('Acc history from Callbacks')\n",
    "plt.savefig('E:/WORKOUT/Statistic/data_sciense_intro/report1/DNN_model/API_merge_sbs_bsb_acc_patience2.png',dpi=300,format='png')\n",
    "plt.close()\n",
    "print('Result saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
